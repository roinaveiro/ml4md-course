{"cells":[{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2018-01-15T19:20:12.319249Z","start_time":"2018-01-15T19:20:12.314813Z"},"id":"q9PlplbnPF_J"},"source":["# **Variational Autoencoder for molecular design**\n","\n","One of the initial proposals to generate molecules using machine learning consisted on employing the concept of [_Variational Autoencoders_](https://arxiv.org/pdf/1312.6114.pdf). These models employ an \"hourglass\" architecture, creating an _information bottleneck_ that serves as latent representation of complex data instances (_e.g._ molecules given as SMILES or with other encoding).\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?id=1-fC0z4n-8Zim6e2XIp4Ggn3aowcLDI84\" width = \"60%\">\n","</center>\n","\n","In order to produce this latent representation, these models consist of two main parts: an **encoder**, which takes as input the initial representation of the desired data (_e.g._ a one-hot encoding of the molecules in the database) and outputs a vector of much smaller dimension that will play the role of the latent representation. After the encoder runs, the **decoder** takes the latent representation and tries to recompose the original input that the encoder received. The whole process is scored in terms of a reconstruction error function, that takes lower values the better the reconstruction for the inputs is. In this particular instance, it means that the model learns to encode and decode molecules to and from a much smaller latent space. \n","\n","Taking these previous ideas, the [original version of this method](https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00572) includes also a **property predictor** that runs from the latent space representation of molecules: once a molecule is encoded into the latent space, its latent representation is fed to an extra model (a neural network) to try to predict the desired tardet function value. This extra network is trained using previously available data, on which each molecule is associated to a measured value of the target property. \n","\n","<center>\n","<img src = 'https://drive.google.com/uc?id=1jBNWRfqdXGOv4cPLL0J1NX1ldOj8egGf' width = \"70%\">\n","</center>\n","\n","With all these components, the authors propose to navigate the latent space to look for molecules that may achieve a better outcome in the target property. In this step they make use of a _Bayesian optimization_ approach to try to find a solution that achieves the highest performance possible in a limited number of steps (since validating each proposal would entail producing a compound and measuring it in a laboratory, which is a costly process). \n"]},{"cell_type":"code","source":["# Mount folder\n","import os, sys\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"metadata":{"id":"-14ggdHxWtiZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685957087970,"user_tz":-120,"elapsed":21363,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"e5d608d5-8fc0-4989-f2ed-8e152d86b6a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Create links and set paths\n","repsol_path = '/content/repsol-ml4md'\n","your_path = '/content/drive/MyDrive/Proyectos/repsol-ml4md/generative_models/variational_autoencoder'\n","os.symlink(your_path, repsol_path) # Set here the path to your directory\n","\n","repsol_utils_path = '/content/repsol-ml4md/utils'\n","sys.path.insert(0,repsol_utils_path)\n","\n","main_dir = './repsol-ml4md/'\n","data_dir = f'{main_dir}data/'\n","data_path = f'{data_dir}processed.zip'\n","utils_dir = f'{main_dir}utils/'"],"metadata":{"id":"L6Vx9QNT4SlV","executionInfo":{"status":"ok","timestamp":1685957093683,"user_tz":-120,"elapsed":489,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Install rdkit for molecule visualization\n","%pip install rdkit-pypi"],"metadata":{"id":"d7L_6cEfjZLY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685957105688,"user_tz":-120,"elapsed":10447,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"4d6f9333-da77-4c55-919c-4d74e1c19dcc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (8.4.0)\n","Installing collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2022.9.5\n"]}]},{"cell_type":"code","source":["# Torch for the heavy-duty calculations\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","# Other packages\n","import gzip\n","import zipfile\n","import pandas\n","import numpy as np\n","import argparse\n","import os\n","import h5py\n","import torch.optim as optim\n","from sklearn import model_selection\n","\n","# Support \n","import mol_utils as mu\n","import json\n","from collections import OrderedDict\n","import yaml\n","from rdkit.Chem import AllChem as Chem\n","from rdkit.Chem import AllChem, Draw"],"metadata":{"id":"2QJLuwPAjXYB","executionInfo":{"status":"ok","timestamp":1685957118597,"user_tz":-120,"elapsed":11717,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["We will define several functions to move around the model. We need these to load the data, convert to (and from) one-hot encoding, etc."],"metadata":{"id":"5HgK7gT5ePKz"}},{"cell_type":"code","source":["def one_hot_array(i, n):\n","    return map(int, [ix == i for ix in xrange(n)])\n","\n","def one_hot_index(vec, charset):\n","    return map(charset.index, vec)\n","\n","def from_one_hot_array(vec):\n","    oh = np.where(vec == 1)\n","    if oh[0].shape == (0, ):\n","        return None\n","    return int(oh[0][0])\n","\n","def decode_smiles_from_indexes(vec, charset):\n","    # print(vec)\n","    # print(charset)\n","    return \"\".join(map(lambda x: charset[x], vec)).strip()\n","\n","\n","def load_dataset(filename, split = True):\n","    h5f = h5py.File(filename, 'r')\n","    if split:\n","        data_train = h5f['data_train'][:]\n","    else:\n","        data_train = None\n","    data_test = h5f['data_test'][:]\n","    # charset =  h5f['charset'][:]\n","    charset = [x.decode() for x in h5f['charset']]\n","    h5f.close()\n","    if split:\n","        return (data_train, data_test, charset)\n","    else:\n","        return (data_test, charset)\n"],"metadata":{"id":"Subsy7K7fz0v","executionInfo":{"status":"ok","timestamp":1685957121047,"user_tz":-120,"elapsed":410,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Declare the path to the file containing all hyperparameters and load them"],"metadata":{"id":"51XvgC2Kec_X"}},{"cell_type":"code","source":["param_path = f'{utils_dir}exp.json'\n","hyper_p = json.loads(open(param_path).read(), object_pairs_hook=OrderedDict)"],"metadata":{"id":"rmPt7MkVzcxK","executionInfo":{"status":"ok","timestamp":1685957124783,"user_tz":-120,"elapsed":1037,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Load the characters available in our database"],"metadata":{"id":"qNVj6bRP4Glz"}},{"cell_type":"code","source":["charset_path = f'{utils_dir}zinc.json' \n","charset = yaml.safe_load(open(charset_path)) # Load the characters present in the \"zinc.json\" file\n","char_indices = dict((c, i) for i, c in enumerate(charset))\n","print(charset)"],"metadata":{"id":"0t8Z8uYQ02z_","executionInfo":{"status":"ok","timestamp":1685957167172,"user_tz":-120,"elapsed":455,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f57ff1d0-ba9a-40d4-a196-15c17a2f12f6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['7', '6', 'o', ']', '3', 's', '(', '-', 'S', '/', 'B', '4', '[', ')', '#', 'I', 'l', 'O', 'H', 'c', '1', '@', '=', 'n', 'P', '8', 'C', '2', 'F', '5', 'r', 'N', '+', '\\\\', ' ']\n"]}]},{"cell_type":"markdown","source":["Extract data files (_this may take a minute..._)"],"metadata":{"id":"G56-vhCeeqgM"}},{"cell_type":"code","source":["zip_ref = zipfile.ZipFile(data_path, 'r')\n","zip_ref.extractall(data_dir)\n","zip_ref.close()"],"metadata":{"id":"jsuB6x9rVL5K","executionInfo":{"status":"ok","timestamp":1685957194161,"user_tz":-120,"elapsed":19762,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Declare the model\n","\n","In this step of the process we define the complete network we will use to encode and decode molecules. This is a basic setup just to show the type of calculations that need to be done to implement the VAE. Since this is a simplified example, _this code does not include the property prediction module_, and thus would need certain extensions to represent the complete original model. This restriction is mostly based on the fact that the original setup can only be run using `tensorflow 1.x`, which is not supported by Collab anymore. Thus, this version is implemented in PyTorch, and is a simpler version of the original setup."],"metadata":{"id":"2URyXX94estQ"}},{"cell_type":"code","source":["class MolecularVAE(nn.Module):\n","\n","    def __init__(self):\n","        super(MolecularVAE, self).__init__()\n","\n","        # Initialize the layer structure for the model\n","\n","        self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n","        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n","        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n","        \n","        self.linear_0 = nn.Linear(70, 435)\n","        self.linear_1 = nn.Linear(435, 292)\n","        self.linear_2 = nn.Linear(435, 292)\n","\n","        self.linear_3 = nn.Linear(292, 292)\n","        self.gru = nn.GRU(292, 501, 3, batch_first=True)\n","        self.linear_4 = nn.Linear(501, 33)\n","        \n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax()\n","\n","    # Encoder: Takes the input (one-hot) and encodes it to the latent space\n","    def encode(self, x):\n","        x = self.relu(self.conv_1(x))\n","        x = self.relu(self.conv_2(x))\n","        x = self.relu(self.conv_3(x))\n","        x = x.view(x.size(0), -1)\n","        x = F.selu(self.linear_0(x))\n","        return self.linear_1(x), self.linear_2(x)\n","\n","    # Sampler: Takes samples from the latent space using a given mean and variance\n","    def sampling(self, z_mean, z_logvar):\n","        epsilon = 1e-2 * torch.randn_like(z_logvar)\n","        return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n","\n","    # Decoder: Takes samples from the latent space and outputs the decoded values\n","    def decode(self, z):\n","        z = F.selu(self.linear_3(z))\n","        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n","        output, hn = self.gru(z)\n","        out_reshape = output.contiguous().view(-1, output.size(-1))\n","        y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n","        y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n","        return y\n","\n","    # Full run: Passes an example through the whole system\n","    def forward(self, x):\n","        z_mean, z_logvar = self.encode(x)\n","        z = self.sampling(z_mean, z_logvar)\n","        return self.decode(z), z_mean, z_logvar"],"metadata":{"id":"J6Mjso_hwdnS","executionInfo":{"status":"ok","timestamp":1685957205360,"user_tz":-120,"elapsed":488,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["The model here is a simple version of the original implementation. The code here describes a basic version for a Variational Autoencoder using 1D-convolutional layers for the encoding and a GRU layer for the decoding, plus additional linear layers and an extra function for the latent-space sampling   "],"metadata":{"id":"WcmKM04rpjSQ"}},{"cell_type":"markdown","source":["We define here the objective function to train the model. It is a combination between the **cross-entropy** loss function and the **KL divergence**, that measures dissimilarity between distributions, which in this context ensures certain structure in the latent space.\n","\n","$$ \n","Loss = CE + KL\n","$$\n","\n","The _cross-entropy_ let us know when the reconstruction of the molecule was successful or not. Thus, we use a binary cross-entropy of the form\n","\n","$$\n","CE(\\mathbf{x},\\mathbf{\\hat{x}}) = - \\sum_i^N p(x_i) \\log p(\\hat{x}_i)\n","$$\n","\n","with $\\mathbf{x}$ and $\\mathbf{\\hat{x}}$ the input and the output from the encoder (_i.e._ the original molecule and the reconstruction) and $p$ the probabilities for the given character in each case (for $\\mathbf{x}$, it is a one-hot encoding of the characters). Intuitively, the CE measures how well the molecule is reconstructed character-wise from the original molecule SMILES.\n","\n","The KL divergence measures the dissimilarity between the latent space distribution and the imposed normal restrictions. This is induced by the latent variable model ([more details](https://arxiv.org/pdf/1312.6114.pdf))\n","$$\n","KL= \\sum_{i=1}^n \\sigma_i^2 + \\mu_i^2 - log(\\sigma_i)-1\n","$$"],"metadata":{"id":"mP5ElJyzgQZu"}},{"cell_type":"code","source":["# Define the reconstruction loss for the VAE\n","def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n","    xent_loss = F.binary_cross_entropy(x_decoded_mean, x, size_average=False)\n","    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n","    return xent_loss + kl_loss"],"metadata":{"id":"gxqESKz6yn6o","executionInfo":{"status":"ok","timestamp":1685957210340,"user_tz":-120,"elapsed":416,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Let us define some parameters for the run"],"metadata":{"id":"xhXMeiQCjkK1"}},{"cell_type":"code","source":["epochs = 1 # 30 # 30 is a reccommended amount of epochs, but we will only do a small test here today\n","batch_size = 250\n","torch_seed = 123\n","\n","torch.manual_seed(torch_seed)\n","\n","# Device (prepared for CUDA)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"Kfo_JrVsyWCo","executionInfo":{"status":"ok","timestamp":1685957241165,"user_tz":-120,"elapsed":615,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["The data has been already pre-processed and turned into one-hot encodings to ease the use. We will import it and load it directly using `torch` functions."],"metadata":{"id":"wIGA90L82Fkx"}},{"cell_type":"code","source":["# Load the data from the processed dataset\n","data_train, data_test, charset = load_dataset(f'{data_dir}processed.h5')\n","data_train = data_train[1:1000]  # Subset, the training procedure is quite expensive and Collab does not support it\n","\n","# Torch functions to load the data, batch-wise\n","data_train = torch.utils.data.TensorDataset(torch.from_numpy(data_train))\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size = batch_size, shuffle=True)"],"metadata":{"id":"Tw5uMb6CqiiC","executionInfo":{"status":"ok","timestamp":1685957268238,"user_tz":-120,"elapsed":2395,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Call the model and declare the optimizer, passing the parameters to be tuned."],"metadata":{"id":"R04Hdqfx2RLU"}},{"cell_type":"code","source":["# Load the model and the optimizer\n","vae = MolecularVAE().to(device)\n","optimizer = optim.Adam(vae.parameters())"],"metadata":{"id":"MCl2Wl_LqcbE","executionInfo":{"status":"ok","timestamp":1685957271133,"user_tz":-120,"elapsed":442,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["To make the procedure more transparent, we will explicitly define the training function below."],"metadata":{"id":"ip5VpisY2Xs1"}},{"cell_type":"code","source":["# Define the training function\n","def train(epoch, model):\n","\n","    model.train()\n","    train_loss = 0\n","\n","    # Batch training\n","    for batch_idx, data in enumerate(train_loader):\n","        \n","        data = data[0].to(device)\n","        optimizer.zero_grad()\n","        output, mean, logvar = model(data)\n","        \n","        # Print initial state of the model\n","        if batch_idx==0:\n","              inp = data.cpu().numpy()\n","              outp = output.cpu().detach().numpy()\n","              lab = data.cpu().numpy()\n","        \n","              print(\"Input:\")\n","              print(decode_smiles_from_indexes(tuple(map(from_one_hot_array, inp[0])), charset))\n","        \n","              print(\"Label:\")\n","              print(decode_smiles_from_indexes(tuple(map(from_one_hot_array, lab[0])), charset))\n","        \n","              sampled = outp[0].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n","              print(\"Output:\")\n","              print(decode_smiles_from_indexes(sampled, charset))\n","        \n","        # Evaluate the loss function and optimize\n","        loss = vae_loss(output, data, mean, logvar)\n","        loss.backward()\n","        train_loss += loss\n","        optimizer.step()\n","\n","        # Print info every certain number of batches\n","        if batch_idx % 1 == 0:\n","              print('Epoch: ' +  str(epoch) + ', batch: ', str(batch_idx))\n","              print('Loss: ' + str(loss))\n","\n","    print('train', train_loss / len(train_loader.dataset))\n","    return train_loss / len(train_loader.dataset)"],"metadata":{"id":"xxvlsvo0mq5R","executionInfo":{"status":"ok","timestamp":1685957274238,"user_tz":-120,"elapsed":611,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Finally, we can _train the model here_. However, keep in mind that this is quite expensive and is unmanageable in basic versions of Collab (even using a small subset of the data for 1 epoch, it takes a while...)"],"metadata":{"id":"rJA0Wuv62f83"}},{"cell_type":"code","source":["# Train the model (careful, this can be expensive)\n","for epoch in range(1, epochs + 1):\n","    train_loss = train(epoch, vae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wevrFw0f4zmF","executionInfo":{"status":"ok","timestamp":1685957363248,"user_tz":-120,"elapsed":82252,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"0aa57c46-1eb2-4414-a249-ab06f007f2b2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n","c1ccc(cc1)c2nnc3n2-c4ccccc4SC3\n","Label:\n","c1ccc(cc1)c2nnc3n2-c4ccccc4SC3\n","Output:\n","6666llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, batch:  0\n","Loss: tensor(134093.2812, grad_fn=<AddBackward0>)\n","Epoch: 1, batch:  1\n","Loss: tensor(118497.4922, grad_fn=<AddBackward0>)\n","Epoch: 1, batch:  2\n","Loss: tensor(67839.4766, grad_fn=<AddBackward0>)\n","Epoch: 1, batch:  3\n","Loss: tensor(111608.1094, grad_fn=<AddBackward0>)\n","train tensor(432.4709, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"markdown","source":["Let us load a somewhat _more trained_ version of the model, that at least is capable of capturing some features about the molecules' SMILES (_e.g._ somewhat produce molecules of similar length). This version is still far from the converged model, needing much more training in order to produce valuable results. We have decided to not pursue further the training of this `torch` implementation of the model because it is quite less functional than the original `tensorflow` implementation. Thus, if you intend to use and explore this model, we encourage you to take a look at the [original code](https://github.com/aspuru-guzik-group/chemical_vae/tree/main).  "],"metadata":{"id":"FOHMZ_8K5IoM"}},{"cell_type":"code","source":["# torch.save(vae.state_dict(), f'{repsol_path}/data/model_example.pt')\n","model = MolecularVAE()\n","model.load_state_dict(torch.load(f'{repsol_path}/data/model_example.pt'))\n","model.eval()"],"metadata":{"id":"06wyRjUSCe9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685957382902,"user_tz":-120,"elapsed":1345,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"bae00dc8-b8ad-48f5-8f36-609832910803"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MolecularVAE(\n","  (conv_1): Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n","  (conv_2): Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n","  (conv_3): Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n","  (linear_0): Linear(in_features=70, out_features=435, bias=True)\n","  (linear_1): Linear(in_features=435, out_features=292, bias=True)\n","  (linear_2): Linear(in_features=435, out_features=292, bias=True)\n","  (linear_3): Linear(in_features=292, out_features=292, bias=True)\n","  (gru): GRU(292, 501, num_layers=3, batch_first=True)\n","  (linear_4): Linear(in_features=501, out_features=33, bias=True)\n","  (relu): ReLU()\n","  (softmax): Softmax(dim=None)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Run the code for the next batch of training data"],"metadata":{"id":"dxlMFhKK5Zvo"}},{"cell_type":"code","source":["example = next(iter(train_loader))[0]\n","example.shape\n","\n","decoded_molecules = mu.hot_to_smiles(example, charset)"],"metadata":{"id":"FXpPaDw6CfMv","executionInfo":{"status":"ok","timestamp":1685957388127,"user_tz":-120,"elapsed":1245,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Plot one of the molecules from the database as an example"],"metadata":{"id":"xFABEgcE5lHu"}},{"cell_type":"code","source":["example_molecule = decoded_molecules[0]\n","\n","print(decoded_molecules[0])\n","Chem.MolFromSmiles(example_molecule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"status":"ok","timestamp":1685957390356,"user_tz":-120,"elapsed":624,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"3b86103f-9b34-414a-f6b1-60cbdfc30f06","id":"CaXfpHuMCfMv"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["CC(=O)Nc1ccc(cc1)NC(=O)COc2ccccc2OC                                                                                     \n"]},{"output_type":"execute_result","data":{"text/plain":["<rdkit.Chem.rdchem.Mol at 0x7f8c611ca650>"],"image/png":"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\n"},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Set up the whole process: encode the example molecules, sample around them in the latent space and then decode the result."],"metadata":{"id":"wzgcetKk5onM"}},{"cell_type":"code","source":["z_mean, z_var = model.encode(example)\n","samples = model.sampling(z_mean, z_var)\n","x_example = model.decode(samples)"],"metadata":{"id":"odSrYhgJCwRy","executionInfo":{"status":"ok","timestamp":1685957414026,"user_tz":-120,"elapsed":7182,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def one_hot_decode(vec, charset):\n","    vec_index = vec.argmax(axis=1)\n","    return \"\".join(map(lambda x: charset[x], vec_index)).strip()\n","\n","def sample_molecules(model, base_molecules, num_per_molecule, charset = charset):\n","    model.eval()\n","    z_mean, z_var = model.encode(base_molecules)\n","    sampled_base_molecules = model.sampling(z_mean, z_var)\n","    encoded_base_molecules = model.decode(sampled_base_molecules)\n","\n","    new_molecules = [ [] for _ in range(len(base_molecules))]\n","\n","    with torch.no_grad():\n","        for i in range(num_per_molecule):\n","            output, mean, std = model.forward(encoded_base_molecules)\n","            for i, mol in enumerate(output):\n","                new_mol = one_hot_decode(mol, charset)\n","                new_molecules[i].append(new_mol)\n","\n","    model.train()\n","    return encoded_base_molecules, new_molecules"],"metadata":{"id":"hl-ZvpYrfejl","executionInfo":{"status":"ok","timestamp":1685957419406,"user_tz":-120,"elapsed":454,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Sample the molecules around each one of the last batch of molecules that we passed through the model. Once properly trained, the model will obtain `n` molecules that are located close to each one of those in the batch.  "],"metadata":{"id":"D-X8mtqo5yZN"}},{"cell_type":"code","source":["enc, new_molecules = sample_molecules(model, example, 2) # The last input controls the number of molecules to be sampled"],"metadata":{"id":"7-dqxBZ0gmU9","executionInfo":{"status":"ok","timestamp":1685957458665,"user_tz":-120,"elapsed":28419,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Character encoding using probabilities in the one-hot dictionary"],"metadata":{"id":"MVG84Liu3fwh"}},{"cell_type":"code","source":["enc[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXOOtxU_mu5l","executionInfo":{"status":"ok","timestamp":1685957550722,"user_tz":-120,"elapsed":628,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"1ef2997d-d86c-4520-eb18-e8a8048f8c85"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.9584e-03, 6.6018e-04, 6.5636e-03,  ..., 6.1783e-03, 1.8086e-03,\n","         2.4926e-04],\n","        [1.2741e-03, 3.6815e-04, 1.0478e-02,  ..., 9.2551e-03, 1.9728e-03,\n","         1.1929e-04],\n","        [1.1370e-03, 3.2764e-04, 1.6108e-02,  ..., 1.1552e-02, 2.3908e-03,\n","         9.2381e-05],\n","        ...,\n","        [9.9976e-01, 4.4031e-06, 2.0160e-05,  ..., 2.6848e-06, 1.3694e-06,\n","         3.5976e-06],\n","        [9.9976e-01, 4.4015e-06, 2.0151e-05,  ..., 2.6835e-06, 1.3685e-06,\n","         3.5966e-06],\n","        [9.9976e-01, 4.4000e-06, 2.0141e-05,  ..., 2.6823e-06, 1.3676e-06,\n","         3.5957e-06]], grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["Show, for example, the two first molecules sampled from the encoding process (_this proves that the model needs much, much more training_)"],"metadata":{"id":"35id8xUw54Ps"}},{"cell_type":"code","source":["new_molecules[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwky_J_1gmLI","executionInfo":{"status":"ok","timestamp":1685957553386,"user_tz":-120,"elapsed":615,"user":{"displayName":"Simón Rodríguez","userId":"13957079860984416057"}},"outputId":"af6fd528-fc55-4be6-d972-d20468d054c0"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Ccccccccccccccccccccccccccccccccccc', 'Ccccccccccccccccccccccccccccccccccc']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["The complete procedure of the model is prepared so that, when coupled with the property prediction part, the model can start out in some point of the latent space corresponding to some molecule (_e.g._ ibuprofen) and then sample molecules increasingly different from the selected one, as can be seen in the figure:\n","\n","<img src='https://drive.google.com/uc?id=1yyh1h9Ogj04-2o8g-EvnLtqPVKIEPWQM' width=\"70%\">\n","\n","Introducing the property prediction allows the model to _sort_ the latent space so that molecules with similar values for the desired property are located closely together. This leads to a structure similar to the following (real) examples from the original paper:\n","\n","<img src='https://drive.google.com/uc?id=1AtI2d_kp1afsqTARrvusFKG_WGgVyi2f' width = \"70%\">\n","\n","In order to optimize the property, we must navigate through the latent space to regions that entail an improvement on the values we are seeking.\n","\n","\n"],"metadata":{"id":"aGehe8QH5CFG"}},{"cell_type":"markdown","source":["> ### Final note:\n","> \n","> The results from this model are, as can be expected due to the low level of training, quite bad. However, this is just an example for the more complete model, written in `tensorflow 1.x`. If you intend to use it, take a look at the [original repository](https://github.com/aspuru-guzik-group/chemical_vae), which is widely documented and quite simple to use (although you have to take care of all dependencies, of course)."],"metadata":{"id":"gtwKZ7mgkoto"}}],"metadata":{"kernelspec":{"display_name":"Python [conda env:miniconda3]","language":"python","name":"conda-env-miniconda3-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"toc_cell":false,"toc_position":{},"toc_section_display":"block","toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}